<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>A survey on datasets for fairness-aware machine learning</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!--<link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">-->

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">
  <link rel="stylesheet" href="css/styles.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!--<link rel="icon" type="image/png" href="images/favicon.png">-->

</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <section class="header">
      <div>
        <!--    <img class="logo" src="fairdata-survey.png" width="200"/> -->
        <h1 class="title">A survey on datasets for fairness-aware machine learning</h1>
      </div>      
    </section>
    <section class="summary">
      <p>
	  As decision-making increasingly relies on machine learning (ML) and (big) data,the issue of fairness in data-driven artificial intelligence systems is receiving increasing attention from both research and industry. 
	  A large variety of fairness-aware ML solutions have been proposed which involve fairness-related interven-tions in the data, learning algorithms, and/or model outputs. 
	  However, a vital part of proposing new approaches is evaluating them empirically on benchmark datasets that represent realistic and diverse settings. 
	  Therefore, in this paper, we overview real-world datasets used for fairness-aware ML. We focus on tabular data as the most common data representation for fairness-aware ML. We start our analysis by identifying relationships between the different attributes, particularly with respect to protected attributes and class attribute, using a Bayesian network. For a deeper understanding of bias in the datasets, we investigate interesting rela-tionships using exploratory analysis.
      </p>
            
      <img src="fairdata-survey.png"" alt="" width="600" height="200" class="center">
      
      <p class="alert" style="text-align:left;">
        Tai Le Quy, Arjun Roy, Vasileios Iosifidis, Wenbin Zhang and Eirini Ntoutsi “A survey on datasetsfor fairness-aware machine learning”. 2022. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery. Wiley Periodicals, Inc. https://doi.org/10.1002/widm.1452
      </p>
    </section>
    
        
    <section class="code-links">
      <a href="https://github.com/tailequy/fairness_dataset" class="button">
        Code
      </a>     
         
      <a href="https://doi.org/10.1002/widm.1452" class="button">
        Paper
      </a>      
     
      
      
    </section>
    <section class="footer">
      tai@l3s.de
      &nbsp; &middot; &nbsp;
      arjun.roy@fu-berlin.de
      &nbsp; &middot; &nbsp;
      iosifidis@l3s.de
      &nbsp; &middot; &nbsp;
	  wenbinzhang@cmu.edu
	  &nbsp; &middot; &nbsp;
	  eirini.ntoutsi@fu-berlin.de
    </section>
  </div>

<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
